{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple linear regression model (Predict SPY)\n",
    "\n",
    "**GOAL**: build a trading model of SPY, based on the historical data of different stock markets.\n",
    "\n",
    "SPY tracks S&P500, the advantages of SPY are:\n",
    "- Cheap: the value of SPY is ~1/10 of S&P500.\n",
    "- Low fees\n",
    "- High volatility\n",
    "\n",
    "Response variable: Price change (Open Price Next Day - Open Price Today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-description\" data-toc-modified-id=\"Data-description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data description</a></span></li><li><span><a href=\"#Data-Munging\" data-toc-modified-id=\"Data-Munging-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Munging</a></span></li><li><span><a href=\"#Data-Spliting---Train-and-Test-samples\" data-toc-modified-id=\"Data-Spliting---Train-and-Test-samples-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Spliting - Train and Test samples</a></span></li><li><span><a href=\"#Explore-the-train-data-set\" data-toc-modified-id=\"Explore-the-train-data-set-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Explore the train data set</a></span></li><li><span><a href=\"#Correlation-between-SPY-and-indices\" data-toc-modified-id=\"Correlation-between-SPY-and-indices-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Correlation between SPY and indices</a></span></li><li><span><a href=\"#Prediction\" data-toc-modified-id=\"Prediction-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Prediction</a></span></li><li><span><a href=\"#Model-evaluation---Statistical-standard\" data-toc-modified-id=\"Model-evaluation---Statistical-standard-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Model evaluation - Statistical standard</a></span></li><li><span><a href=\"#Evaluating-strategy-built-from-Regression-model\" data-toc-modified-id=\"Evaluating-strategy-built-from-Regression-model-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluating strategy built from Regression model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Profit-of-Signal-based-strategy\" data-toc-modified-id=\"Profit-of-Signal-based-strategy-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Profit of Signal-based strategy</a></span></li><li><span><a href=\"#Evaluation-using-Risk-measures---Sharpe-&amp;-Maximum-Drawdown\" data-toc-modified-id=\"Evaluation-using-Risk-measures---Sharpe-&amp;-Maximum-Drawdown-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Evaluation using Risk measures - Sharpe &amp; Maximum Drawdown</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description\n",
    "\n",
    "Different markets - different time zones.\n",
    "- Eastern Time (ET) for US: 9:00AM - 4:00PM.\n",
    "- Eastern Time (ET) for EU: 3:00AM - 11:30AM.\n",
    "- Eastern Time (ET) for Asia: 8:00PM(yesterday) - 3:00AM\n",
    "\n",
    "When US market opens - Asian market information(Open & Close) is available. Updated data for European market (besides Close) is also available.\n",
    "\n",
    "**Asian markets including Australia**\n",
    "- **aord** - The All Ordinaries (XAO) or \"All Ords\" is considered a total market barometer for the Australian stock market and contains the 500 largest ASX listed companies by way of market capitalisation.\n",
    "- **nikkei** - The Nikkei 225, more commonly called the Nikkei is a stock market index for the Tokyo Stock Exchange (TSE).\n",
    "- **hsi** - Hong Kong, Hang Seng Index (HSI)\n",
    "\n",
    "**Europe**\n",
    "- **daxi** - The DAX is a blue chip stock market index consisting of the 30 major German companies trading on the Frankfurt Stock Exchange. \n",
    "- **cac40** - The CAC 40 (Cotation AssistÃ©e en Continu) is a benchmark French stock market index.\n",
    "\n",
    "**US**\n",
    "- **sp500** - The S&P 500 is a stock market index that measures the stock performance of 500 large companies listed on stock exchanges in the United States.\n",
    "- **dji** - The Dow Jones Industrial Average is a stock market index that tracks the stock prices of the top 30 U.S. companies. Analysts use it to gauge the health of the stock market. It reflects investors' confidence in those companies and in the economy overall.\n",
    "- **nasdaq** - The Nasdaq Composite Index is the market capitalization-weighted index of over 3,300 common equities listed on the Nasdaq stock exchange.\n",
    "- **spy** - The SPDR S&P 500 trust is an exchange-traded fund. It is designed to track the S&P 500 stock market index. This fund is the largest ETF in the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all stock market data into DataFrame\n",
    "aord = pd.read_csv('data/signal_based_trading_strategy/ALLOrdinary.csv', index_col = 0)\n",
    "nikkei = pd.read_csv('data/signal_based_trading_strategy/Nikkei225.csv', index_col = 0)\n",
    "hsi = pd.read_csv('data/signal_based_trading_strategy/HSI.csv', index_col = 0)\n",
    "daxi = pd.read_csv('data/signal_based_trading_strategy/DAXI.csv', index_col = 0)\n",
    "cac40 = pd.read_csv('data/signal_based_trading_strategy/CAC40.csv', index_col = 0)\n",
    "sp500 = pd.read_csv('data/signal_based_trading_strategy/SP500.csv', index_col = 0)\n",
    "dji = pd.read_csv('data/signal_based_trading_strategy/DJI.csv', index_col = 0)\n",
    "nasdaq = pd.read_csv('data/signal_based_trading_strategy/nasdaq_composite.csv', index_col = 0)\n",
    "spy = pd.read_csv('data/signal_based_trading_strategy/SPY.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Munging\n",
    "Due to the timezone issues, we extract and calculate appropriate stock market data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicepanel is the DataFrame of our trading model\n",
    "# Start with an empty dataframe with an index (Date) matching spy\n",
    "indicepanel=pd.DataFrame(index=spy.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposen variable:\n",
    "indicepanel['spy']=spy['Open'].shift(-1)-spy['Open'] # spy.Open(t+1) - spy.Open(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors:\n",
    "\n",
    "# The difference between spy.Open(t+1) - spy.Open(t) is only observed at (t+1) thus we shift our calculations `down` by 1 row.\n",
    "indicepanel['spy_lag1']=indicepanel['spy'].shift(1) # Shift result to (t+1)\n",
    "\n",
    "# Open Today - Open Last Day\n",
    "indicepanel['sp500']=sp500[\"Open\"]-sp500['Open'].shift(1) # Open(t) - Open(t-1)\n",
    "indicepanel['nasdaq']=nasdaq['Open']-nasdaq['Open'].shift(1)\n",
    "indicepanel['dji']=dji['Open']-dji['Open'].shift(1)\n",
    "\n",
    "# Todays and yesterday Open price is available.\n",
    "# Ideally for EU markets we would want to use Open price during noon (intraday) \n",
    "# as it is available at the time when US market opens.\n",
    "indicepanel['cac40']=cac40['Open']-cac40['Open'].shift(1)\n",
    "indicepanel['daxi']=daxi['Open']-daxi['Open'].shift(1)\n",
    "\n",
    "# Asian\n",
    "# Close and Open prices are available for Asian markets.\n",
    "indicepanel['aord']=aord['Close']-aord['Open']\n",
    "indicepanel['hsi']=hsi['Close']-hsi['Open']\n",
    "indicepanel['nikkei']=nikkei['Close']-nikkei['Open']\n",
    "\n",
    "# Last column - Open price of SPY which will be used in trading.\n",
    "indicepanel['Price']=spy['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicepanel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check whether do we have NaN values in indicepanel\n",
    "# Different market has different holiday periods in which the markets are closed.\n",
    "# This generates NaN values.\n",
    "indicepanel.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use method 'fillna()' from dataframe to forward filling the Nan values\n",
    "# Then we can drop the reminding Nan values\n",
    "indicepanel = indicepanel.fillna(method='ffill')\n",
    "indicepanel = indicepanel.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check whether do we have Nan values in indicepanel now\n",
    "indicepanel.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save merged dataframe\n",
    "path_save = 'data/signal_based_trading_strategy/indicepanel.csv'\n",
    "indicepanel.to_csv(path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indicepanel.shape)\n",
    "# We have 2677 days of data, 1 Response variable, 9 Predictors and \n",
    "# last collumn keeps a record of Open price of SPY which will be used in Paper Trading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Spliting - Train and Test samples\n",
    "\n",
    "To make sure that our model is consistent in future data, we need to split data into two parts:\n",
    "- one is for building the model (TRAIN)\n",
    "- the other part is for testing the model to see if the model can still make reasonable prediction in this dataset. (TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into (1)train set and (2)test set\n",
    " \n",
    "Train = indicepanel.iloc[-2000:-1000, :] # 1,000 days before TEST\n",
    "Test = indicepanel.iloc[-1000:, :] # The most recent 1,000 days.\n",
    "print(Train.shape, Test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate scatter matrix among all stock markets (and the price of SPY) to observe the association\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "sm = scatter_matrix(Train, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between SPY and indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the indice with largest correlation\n",
    "corr_array = Train.iloc[:, :-1].corr()['spy']\n",
    "print(corr_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build OLS Regression model**\n",
    "\n",
    "- Prob(F-statistic): Significance of the overall model. Testing against H0, which states that all $\\beta$ values are equal to 0. Alternative hypothesis states that at least one of them is not zero. Low Prob(F-statistic) indicates that model includes useful predictors.\n",
    "- P>|t| - probability values for each predictor. We see that most of the predictors are not significant except AORD. **This can be caused by Multicollinarity**, where two or more predicotrs are highly, linearly related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'spy~spy_lag1+sp500+nasdaq+dji+cac40+aord+daxi+nikkei+hsi'\n",
    "lm = smf.ols(formula=formula, data=Train).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['PredictedY'] = lm.predict(Train)\n",
    "Test['PredictedY'] = lm.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot between real daily change and predicted\n",
    "# We see a positive correlation, although not very strong one.\n",
    "plt.scatter(Train['spy'], Train['PredictedY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation - Statistical standard\n",
    "We can measure the performance of our model using some statistical metrics - RMSE, Adjusted $R^2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE - Root Mean Squared Error, Adjusted R^2\n",
    "def adjustedMetric(data, model, model_k, yname):\n",
    "    data['yhat'] = model.predict(data)\n",
    "    SST = ((data[yname] - data[yname].mean())**2).sum()\n",
    "    SSR = ((data['yhat'] - data[yname].mean())**2).sum()\n",
    "    SSE = ((data[yname] - data['yhat'])**2).sum()\n",
    "    r2 = SSR/SST\n",
    "    adjustR2 = 1 - (1-r2)*(data.shape[0] - 1)/(data.shape[0] -model_k -1)\n",
    "    RMSE = (SSE/(data.shape[0] -model_k -1))**0.5\n",
    "    return adjustR2, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate output: compare r-squared and RMSE for Train and Test data.\n",
    "def assessTable(test, train, model, model_k, yname):\n",
    "    r2test, RMSEtest = adjustedMetric(test, model, model_k, yname)\n",
    "    r2train, RMSEtrain = adjustedMetric(train, model, model_k, yname)\n",
    "    assessment = pd.DataFrame(index=['R2', 'RMSE'], columns=['Train', 'Test'])\n",
    "    assessment['Train'] = [r2train, RMSEtrain]\n",
    "    assessment['Test'] = [r2test, RMSEtest]\n",
    "    return assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the assement table fo our model\n",
    "assessTable(Test, Train, lm, 9, 'spy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether R-squared and RMSE are different dramatically between TRAIN and TEST. If so, it is called **overfitting**. Usually, for overfitting model, RMSE and adjusted R-squared is much better in train than in test dataset. This would imply that we cannot apply this model to real market in future. \n",
    "\n",
    "If we look at our output - we see that RMSE slighly increases in TEST, but overall - model does not seem to be overfitted. Adjusted R-squared is on the low side (~6%), but this is normal when dealing with a stock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(Train, Test, aord, cac40, corr_array, daxi, dji, formula, hsi, indicepanel, lm, nasdaq, nikkei, path_save, sm, sp500, spy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating strategy built from Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the combined dataset\n",
    "indicepanel = pd.read_csv('data/signal_based_trading_strategy/indicepanel.csv', index_col = 0)\n",
    "indicepanel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Train and Test parts\n",
    "Train = indicepanel.iloc[-2000:-1000, :]\n",
    "Test = indicepanel.iloc[-1000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple regression model\n",
    "formula = 'spy~spy_lag1+sp500+nasdaq+dji+cac40+aord+daxi+nikkei+hsi'\n",
    "lm = smf.ols(formula=formula, data=Train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['PredictedY'] = lm.predict(Train)\n",
    "Test['PredictedY'] = lm.predict(Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit of Signal-based strategy\n",
    "\n",
    "Given the predicted values of SPY return (`PredictedY`), we create a signal where `1` corresponds to `LONG` and `-1` to `SHORT`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "Train['Order'] = [1 if sig>0 else -1 for sig in Train['PredictedY']]\n",
    "Train['Profit'] = Train['spy'] * Train['Order']\n",
    "\n",
    "Train['Wealth'] = Train['Profit'].cumsum()\n",
    "print('Total profit made in Train: ', Train['Profit'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Performance of Strategy in Train')\n",
    "plt.plot(Train['Wealth'].values, color='green', label='Signal based strategy')\n",
    "plt.plot(Train['spy'].cumsum().values, color='red', label='Buy and Hold strategy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that signal based strategy outperforms a passive Buy and Hold strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "Test['Order'] = [1 if sig>0 else -1 for sig in Test['PredictedY']]\n",
    "Test['Profit'] = Test['spy'] * Test['Order']\n",
    "\n",
    "Test['Wealth'] = Test['Profit'].cumsum()\n",
    "print('Total profit made in Test: ', Test['Profit'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The consistency of performance is very important. Otherwise, it is too risky to apply it in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Performance of Strategy in TEST')\n",
    "plt.plot(Test['Wealth'].values, color='green', label='Signal based strategy')\n",
    "plt.plot(Test['spy'].cumsum().values, color='red', label='Buy and Hold strategy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using Risk measures - Sharpe & Maximum Drawdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce two common practical standards - **Sharpe Ratio**, **Maximum Drawdown** to evaluate our model performance.\n",
    "\n",
    "Sharpe - measures excess return per unit of risk (risk is measured using standard deviation of excess return).\n",
    "\n",
    "Maximum drawdown - the maximum percentage decline in the strategy from the historical peak profit at each point in time. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include initial invesment (1 share of SPY)\n",
    "Train['Wealth'] = Train['Wealth'] + Train.loc[Train.index[0], 'Price']\n",
    "Test['Wealth'] = Test['Wealth'] + Test.loc[Test.index[0], 'Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharpe Ratio on Train data\n",
    "Train['Return'] = np.log(Train['Wealth']) - np.log(Train['Wealth'].shift(1))\n",
    "dailyr = Train['Return'].dropna()\n",
    "\n",
    "print('Daily Sharpe Ratio is ', dailyr.mean()/dailyr.std(ddof=1))\n",
    "print('Yearly Sharpe Ratio is ', (252**0.5)*dailyr.mean()/dailyr.std(ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharpe Ratio in Test data\n",
    "Test['Return'] = np.log(Test['Wealth']) - np.log(Test['Wealth'].shift(1))\n",
    "dailyr = Test['Return'].dropna()\n",
    "\n",
    "print('Daily Sharpe Ratio is ', dailyr.mean()/dailyr.std(ddof=1))\n",
    "print('Yearly Sharpe Ratio is ', (252**0.5)*dailyr.mean()/dailyr.std(ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Drawdown in Train data\n",
    "Train['Peak'] = Train['Wealth'].cummax()\n",
    "Train['Drawdown'] = (Train['Peak'] - Train['Wealth'])/Train['Peak']\n",
    "print('Maximum Drawdown in Train is ', Train['Drawdown'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Drawdown in Test data\n",
    "Test['Peak'] = Test['Wealth'].cummax()\n",
    "Test['Drawdown'] = (Test['Peak'] - Test['Wealth'])/Test['Peak']\n",
    "print('Maximum Drawdown in Test is ', Test['Drawdown'].max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "582px",
    "left": "1573px",
    "right": "20px",
    "top": "120px",
    "width": "327px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
